{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f07f38",
   "metadata": {},
   "source": [
    "## Overview of dataset\n",
    "\n",
    "Book recommendation dataset from kaggle: http://www.kaggle.com/datasets/arashnic/book-recommendation-dataset\n",
    "\n",
    "The Book-Crossing dataset comprises 3 files.\n",
    "\n",
    "Users:\n",
    "\n",
    "Contains the users. Note that user IDs (User-ID) have been anonymized and map to integers. Demographic data is provided (Location, Age) if available. Otherwise, these fields contain NULL-values.\n",
    "\n",
    "Books:\n",
    "\n",
    "Books are identified by their respective ISBN. Invalid ISBNs have already been removed from the dataset. Moreover, some content-based information is given (Book-Title, Book-Author, Year-Of-Publication, Publisher), obtained from Amazon Web Services. Note that in case of several authors, only the first is provided. URLs linking to cover images are also given, appearing in three different flavours (Image-URL-S, Image-URL-M, Image-URL-L), i.e., small, medium, large. These URLs point to the Amazon web site.\n",
    "\n",
    "Ratings:\n",
    "\n",
    "Contains the book rating information. Ratings (Book-Rating) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0.\n",
    "The dataset is from the site https://www.bookcrossing.com/howto.\n",
    "\n",
    "Collected by Cai-Nicolas Ziegler in a 4-week crawl (August / September 2004) from the Book-Crossing community with kind permission from Ron Hornbaker, CTO of Humankind Systems. Contains 278,858 users (anonymized but with demographic information) providing 1,149,780 ratings (explicit / implicit) about 271,379 books. I [dataset uploader, Möbius] preprocessed and cleaned data format.\n",
    "\n",
    "Books.csv has 271360 observations and 8 variables. Predictors include Book-Author, Year-of-Publication, and Publisher.\n",
    "\n",
    "Ratings.csv has 1,149,780 observations and 3 variables. Predictors include Book-Rating.\n",
    "Users.csv has 278,858 observations and 3 variables. Predictors include Location and Age.\n",
    "\n",
    "There are primary and foreign keys in the csv files so the different tables can reference each other. These include User-ID and ISBN.\n",
    "\n",
    "We will likely be working with Book-Rating, Location, Book-Author, Year-of-Publication, and Publisher (along with User-ID and ISBN) to build our recommendation system.\n",
    "\n",
    "There are 110762 missing values for Age, and 2-3 missing values for some other variables. This means about 40% of Age is missing. Since there is so much, we will likely drop this variable altogether. The other variables (Book-Author, Publisher) have a negligible number of missing values, and dropping the rows should not affect the overall dataset much, so that’s what we’ll likely do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5ae472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54563929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "users_df = pd.read_csv('data/Users.csv')\n",
    "books_df = pd.read_csv('data/Books.csv', low_memory=False)\n",
    "ratings_df = pd.read_csv('data/Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a97f0c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in ratings_df:\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in books_df:\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values in users_df:\n",
      "User-ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missingness for each dataframe\n",
    "print(\"Missing values in ratings_df:\")\n",
    "print(ratings_df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Missing values in books_df:\")\n",
    "print(books_df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Missing values in users_df:\")\n",
    "print(users_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948842e6",
   "metadata": {},
   "source": [
    "## Overview of research questions\n",
    "\n",
    "Given a user's historical book interactions, can we recommend books they are likely to enjoy?\n",
    "\n",
    "How similar are books based on their content (titles, authors, genres), and can we use this similarity to make personalized recommendations?\n",
    "\n",
    "The users of the recommendation system will provide the information, including: locations, age, several favorite books, and ratings on books, as a basis for the recommendation. On the User data set, we can easily find out the book lists of people who have similar locations and ages to the users. That list of books can potentially be the recommended book list based on their similarities. In addition, we can also find a recommended book list based on the user’s preferences for books. Users may also like the books of people who have common preferences, such as the same favorite books or the same ratings on certain books. What’s more, we may also order the recommendation book lists based on variables, such as author, publisher, and year of publication.\n",
    "\n",
    "The goal of this project is to recommend books to system users, so it is a combination of predictive and descriptive. The system needs to predict books that users may be interested in and present them based on the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc59a2a",
   "metadata": {},
   "source": [
    "## Proposed Project Timeline\n",
    "\n",
    "- Week 5:  EDA\n",
    "- Week 6: EDA\n",
    "- Week 7: Run models\n",
    "- Week 8: Run models\n",
    "- Week 9: Rough Draft\n",
    "- Week 10: Final Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd666797",
   "metadata": {},
   "source": [
    "## Questions or Concerns\n",
    "\n",
    "Do we use content-based or collaborative recommendations? Both?\n",
    "\n",
    "Do we need to split into train/test sets?\n",
    "\n",
    "What are the pros and cons of using Python vs R for a recommendation system?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pstat134project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
